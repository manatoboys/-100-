{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Morph():\n",
    "    def __init__(self, doc_list):\n",
    "        self.surface = doc_list[0]\n",
    "        self.base = doc_list[7]\n",
    "        self.pos = doc_list[1]\n",
    "        self.pos1= doc_list[2]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{\" + f\"surface: {self.surface}, base: {self.base}, pos: {self.pos}, pos1: {self.pos1}\" + \"}\"\n",
    "\n",
    "class Chunk():\n",
    "    def __init__(self,morph_list,dst,srcs):\n",
    "        self.morph_list = morph_list\n",
    "        self.dst = int(dst)\n",
    "        self.srcs = srcs\n",
    "\n",
    "    def __str__(self):\n",
    "        morphs_str = ', '.join(str(morph) for morph in self.morph_list) # Morphオブジェクトのリストを文字列に変換\n",
    "        return f\"Morphs: [{morphs_str}], Dst: {self.dst}, Srcs: {self.srcs}\"\n",
    "\n",
    "# 文節番号と係り先番号の取得\n",
    "def find_feature_number(text):\n",
    "    pattern = r\"^\\* \\d+ ([^\\d]*\\d+)D\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        dst_number = match.group(1)  # 文節番号  # 係先番号\n",
    "        return dst_number\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"ai.ja.txt.parsed\", mode=\"r\", encoding=\"utf-8\")as f:\n",
    "    docs = f.readlines()\n",
    "\n",
    "Chunk_list = []\n",
    "chunk_flag = False\n",
    "# srcの追加処理は後で行う\n",
    "for doc in docs[5:]:\n",
    "    if doc == \"EOS\\n\":\n",
    "        chunk = Chunk(morph_list,dst_num,[])\n",
    "        Chunk_list.append(chunk)\n",
    "        break\n",
    "    # *から始まる行とEOSの行は飛ばす\n",
    "    if doc[0]==\"*\":\n",
    "        if chunk_flag:\n",
    "            chunk = Chunk(morph_list,dst_num,[])\n",
    "            Chunk_list.append(chunk)\n",
    "        dst_num = find_feature_number(doc)\n",
    "        morph_list = []\n",
    "        chunk_flag = True\n",
    "    else:\n",
    "        doc = doc.replace(\"\\t\",\",\").replace(\"\\n\", \"\")\n",
    "        doc_list = doc.split(\",\")\n",
    "        doc_morph = Morph(doc_list)\n",
    "        morph_list.append(doc_morph)\n",
    "\n",
    "\n",
    "# Srcsを埋めていく\n",
    "for i in range(len(Chunk_list)):\n",
    "    Chunk_list[Chunk_list[i].dst].srcs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "道具を\t用いて\n",
      "知能を\t研究する\n",
      "一分野を\t指す\n",
      "知的行動を\t代わって\n",
      "人間に\t代わって\n",
      "コンピューターに\t行わせる\n",
      "研究分野とも\tされる\n"
     ]
    }
   ],
   "source": [
    "# 41を再利用していく\n",
    "\n",
    "# morphのsurfaceのみを抽出して，文章を再構築する\n",
    "def get_sentence(chunk: Chunk):\n",
    "    remove_list = [\"（\", \"）\", \"、\", \"。\", \"「\", \"」\", \"『\", \"』\", \"〈\", \"〉\"]\n",
    "    morph_list = chunk.morph_list\n",
    "    sentence_str = \"\"\n",
    "    for morph in morph_list:\n",
    "        if morph.surface in remove_list:\n",
    "            continue\n",
    "        sentence_str += morph.surface\n",
    "    return sentence_str\n",
    "\n",
    "# typeはnoun or verb　のみ\n",
    "def has_type_in_sentence(chunk: Chunk, pos) -> bool:\n",
    "    morph_list = chunk.morph_list\n",
    "    if pos == \"noun\":\n",
    "        for morph in morph_list:\n",
    "            if morph.pos == \"名詞\":\n",
    "                return True\n",
    "        return False\n",
    "    elif pos == \"verb\":\n",
    "        for morph in morph_list:\n",
    "            if morph.pos == \"動詞\":\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Invalid type. Put noun or verb into pos.\")\n",
    "\n",
    "for chunk in Chunk_list:\n",
    "    src_morph = chunk\n",
    "    dst_morph = Chunk_list[chunk.dst]\n",
    "    has_noun_in_src_sentence = has_type_in_sentence(src_morph, \"noun\")\n",
    "    has_verb_in_dst_sentence = has_type_in_sentence(dst_morph, \"verb\")\n",
    "    if  has_noun_in_src_sentence and has_verb_in_dst_sentence:\n",
    "        result = get_sentence(src_morph) + \"\\t\" + get_sentence(dst_morph)\n",
    "        print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

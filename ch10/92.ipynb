{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tajiri/.local/lib/python3.8/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/tajiri/.local/lib/python3.8/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/tajiri/.local/lib/python3.8/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "FILE_PATH = \"./wiki_corpus_2.01/kyoto_lexicon.csv\"\n",
    "tokenizer_src = get_tokenizer('spacy', language='ja_core_news_sm')\n",
    "tokenizer_tgt = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "# どれか一つの行がうまく読み込めなかったため、truncate_tagged_linesでfield数が一致しない行は無視している(元データ51983行)\n",
    "\n",
    "class datasets(Dataset):\n",
    "    def __init__(self, text, label):\n",
    "        self.jp_datas = text\n",
    "        self.en_datas = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len (self.jp_datas)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        jp = self.jp_datas[index]\n",
    "        en = self.en_datas[index]\n",
    "        return jp,en\n",
    "\n",
    "class DataLoaderCreater:\n",
    "\n",
    "    def __init__(self, file_path, src_tokenizer, tgt_tokenizer):\n",
    "        self.file_path = file_path\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def build_vocab(self, texts, tokenizer):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(tokenizer(text))\n",
    "        specials = ['<unk>', '<pad>', '<start>', '<end>']\n",
    "        v = vocab(counter, specials=specials, min_freq=1)\n",
    "        v.set_default_index(v['<unk>'])\n",
    "        return v\n",
    "\n",
    "    def convert_text_to_indexes(self, text, vocab, tokenizer):\n",
    "        return [vocab['<start>']] + [\n",
    "            vocab[token] if token in vocab else vocab['<unk>'] for token in tokenizer(text.strip(\"\\n\"))\n",
    "        ] + [vocab['<end>']]\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        df = pl.read_csv(self.file_path, separator=\",\", encoding=\"utf-8\", has_header=True, truncate_ragged_lines=True)\n",
    "        df_selected = df.select([df.columns[0], df.columns[1]])\n",
    "        df_jp = df_selected[:, 0]\n",
    "        jp_list = df_jp.to_list()\n",
    "        df_en = df_selected[:, 1]\n",
    "        en_list = df_en.to_list()\n",
    "\n",
    "        self.vocab_src = self.build_vocab(jp_list, tokenizer_src)\n",
    "        self.vocab_tgt = self.build_vocab(en_list, tokenizer_tgt)\n",
    "        self.vocab_src_index_to_word = self.vocab_src.get_itos()\n",
    "        self.vocab_tgt_index_to_word = self.vocab_tgt.get_itos()\n",
    "        self.vocab_src = self.vocab_src.get_stoi()\n",
    "        self.vocab_tgt = self.vocab_tgt.get_stoi()\n",
    "        self.len_src_vocab = len(self.vocab_src)\n",
    "        self.len_tgt_vocab = len(self.vocab_tgt)\n",
    "\n",
    "        src_data = pad_sequence([torch.tensor(self.convert_text_to_indexes(text, self.vocab_src, tokenizer=self.src_tokenizer)) for text in jp_list], batch_first = True, padding_value = self.vocab_src[\"<pad>\"])\n",
    "        tgt_data = pad_sequence([torch.tensor(self.convert_text_to_indexes(text, self.vocab_tgt, tokenizer=self.tgt_tokenizer)) for text in en_list], batch_first = True, padding_value = self.vocab_tgt[\"<pad>\"])\n",
    "\n",
    "        dataset = datasets(src_data, tgt_data)\n",
    "\n",
    "        # データセットの長さを取得\n",
    "        dataset_length = len(dataset)\n",
    "\n",
    "        # 各分割のサイズを計算\n",
    "        train_size = int(0.8 * dataset_length)\n",
    "        val_size = int(0.1 * dataset_length)\n",
    "        test_size = dataset_length - train_size - val_size\n",
    "\n",
    "        # データセットをランダムに分割\n",
    "        train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size=128)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "        return train_dataloader, test_dataloader, valid_dataloader\n",
    "\n",
    "dataloader_creater = DataLoaderCreater(FILE_PATH, tokenizer_src, tokenizer_tgt)\n",
    "train_dataloader, test_dataloader, valid_dataloader = dataloader_creater.create_dataloader()\n",
    "src_vocab_size = dataloader_creater.len_src_vocab\n",
    "tgt_vocab_size = dataloader_creater.len_tgt_vocab\n",
    "vocab_src = dataloader_creater.vocab_src\n",
    "vocab_tgt = dataloader_creater.vocab_tgt\n",
    "# インデックス列を文字列に変換\n",
    "vacab_src_index_to_word = dataloader_creater.vocab_src_index_to_word\n",
    "vacab_tgt_index_to_word = dataloader_creater.vocab_tgt_index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding_src): Embedding(30957, 512)\n",
       "  (embedding_tgt): Embedding(37917, 512)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0, inplace=False)\n",
       "          (dropout2): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0, inplace=False)\n",
       "          (dropout2): Dropout(p=0, inplace=False)\n",
       "          (dropout3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=512, out_features=37917, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "# EncodingとEmbeddingの違い\n",
    "# 学習を行わないのがPositional Encoding\n",
    "# 学習を行うのがPositional Embedding\n",
    "\n",
    "class PositionalEncoding():\n",
    "    def __init__(self, embedding_dim, len_sequence):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.len_sequence = len_sequence\n",
    "\n",
    "    def get_sin(self,i,k):\n",
    "        return math.sin(i/(10000)**(k/self.len_sequence))\n",
    "\n",
    "    def get_cos(self,i,k):\n",
    "        return math.cos(i/(10000)**(k/self.len_sequence))\n",
    "    \n",
    "    def get_positional_vector(self):\n",
    "        pe = torch.zeros(self.len_sequence, self.embedding_dim)\n",
    "        for pos in range(self.len_sequence):\n",
    "            for i in range(0, int(self.embedding_dim/2)):\n",
    "                pe[pos, 2*i] = self.get_sin(pos, i)\n",
    "                pe[pos, 2*i+1] = self.get_cos(pos, i)\n",
    "        return pe\n",
    "\n",
    "\n",
    "# Transformerモデルの定義\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size_src, vocab_size_tgt, embedding_dim, num_heads, num_layers, device,  dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        # Positional Encoderを加算する必要あり\n",
    "        self.embedding_src = nn.Embedding(vocab_size_src, embedding_dim)\n",
    "        self.embedding_tgt = nn.Embedding(vocab_size_tgt, embedding_dim)\n",
    "        self.pos_embedding_src = PositionalEncoding(embedding_dim, 33)\n",
    "        self.pos_embedding_tgt = PositionalEncoding(embedding_dim, 73)\n",
    "        self.transformer = nn.Transformer(d_model=embedding_dim, nhead=num_heads, num_encoder_layers=num_layers, num_decoder_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(embedding_dim, vocab_size_tgt)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding_src(src)\n",
    "        tgt = self.embedding_tgt(tgt)\n",
    "        batch_size = src.shape[0]\n",
    "        pos_src = self.pos_embedding_src.get_positional_vector().to(device)\n",
    "        pos_src = pos_src.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        pos_tgt = self.pos_embedding_tgt.get_positional_vector().to(device)\n",
    "        pos_tgt = pos_tgt.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        src = src + pos_src\n",
    "        tgt = tgt + pos_tgt\n",
    "        output = self.transformer(src, tgt)\n",
    "        output = self.fc_out(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# モデルのハイパーパラメータ\n",
    "embedding_dim = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')\n",
    "# モデルの初期化\n",
    "# モデルの初期化\n",
    "model = TransformerModel(src_vocab_size, tgt_vocab_size, embedding_dim, num_heads, num_layers, device, dropout=0).to(device)\n",
    "\n",
    "# 保存された重みをロード\n",
    "model.load_state_dict(torch.load(\"./model_weight.pth\", map_location=device))\n",
    "model.eval()  # モデルを評価モードに設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# インデックスから単語に変換する関数\n",
    "def indexes_to_sentence(indexes, vocab_index_to_word):\n",
    "    return ' '.join([vocab_index_to_word[idx] for idx in indexes])\n",
    "\n",
    "# 翻訳関数\n",
    "def translate_sentence(model, sentence, src_vocab, tgt_vocab, src_tokenizer, src_vocab_index_to_word, tgt_vocab_index_to_word, device, max_len=73):\n",
    "    model.eval()\n",
    "    tokens = [src_vocab['<start>']] + [src_vocab.get(token, src_vocab['<unk>']) for token in src_tokenizer(sentence)] + [src_vocab['<end>']]\n",
    "    src_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    src_tensor = F.pad(src_tensor, (0, 33 - src_tensor.shape[1]), 'constant', src_vocab['<pad>'])\n",
    "    \n",
    "    # エンコーダの出力を取得\n",
    "    memory = model.transformer.encoder(model.embedding_src(src_tensor) + model.pos_embedding_src.get_positional_vector().unsqueeze(0).to(device))\n",
    "\n",
    "    # デコーダの入力\n",
    "    tgt_indexes = [tgt_vocab['<start>']]\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        tgt_tensor = torch.tensor(tgt_indexes).unsqueeze(0).to(device)\n",
    "        tgt_tensor = F.pad(tgt_tensor, (0, 73 - tgt_tensor.shape[1]), 'constant', tgt_vocab['<pad>'])\n",
    "        \n",
    "        # デコーダの出力を取得\n",
    "        output = model.transformer.decoder(model.embedding_tgt(tgt_tensor) + model.pos_embedding_tgt.get_positional_vector().unsqueeze(0).to(device), memory)\n",
    "        output = model.fc_out(output)\n",
    "        next_token = output.argmax(2)[:, len(tgt_indexes) - 1].item()\n",
    "        tgt_indexes.append(next_token)\n",
    "        \n",
    "        if next_token == tgt_vocab['<end>']:\n",
    "            break\n",
    "    \n",
    "    translated_sentence = indexes_to_sentence(tgt_indexes, tgt_vocab_index_to_word)\n",
    "    return translated_sentence\n",
    "\n",
    "# 任意の日本語の文章\n",
    "jp_sentence = \"こんにちは、元気ですか？\"\n",
    "\n",
    "# 翻訳の実行\n",
    "translated_sentence = translate_sentence(model, jp_sentence, vocab_src, vocab_tgt, tokenizer_src, vacab_src_index_to_word, vacab_tgt_index_to_word, device)\n",
    "print(translated_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

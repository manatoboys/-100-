{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tajiri/.local/lib/python3.8/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/tajiri/.local/lib/python3.8/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/tajiri/.local/lib/python3.8/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "JP_TRAIN_FILE_PATH = \"./kftt-data-1.0/data/orig/kyoto-train.ja\"\n",
    "EN_TRAIN_FILE_PATH = \"./kftt-data-1.0/data/orig/kyoto-train.en\"\n",
    "\n",
    "tokenizer_src = get_tokenizer('spacy', language='ja_core_news_sm')\n",
    "tokenizer_tgt = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "with open(JP_TRAIN_FILE_PATH, \"r\", encoding=\"utf-8\")as f:\n",
    "    train_jp_list = f.readlines()\n",
    "    train_jp_list = [jp.strip(\"\\n\") for jp in train_jp_list]\n",
    "\n",
    "with open(EN_TRAIN_FILE_PATH, \"r\", encoding=\"utf-8\")as f:\n",
    "    train_en_list = f.readlines()\n",
    "    train_en_list = [en.strip(\"\\n\") for en in train_en_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasets(Dataset):\n",
    "    def __init__(self, text, label):\n",
    "        self.jp_datas = text\n",
    "        self.en_datas = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.jp_datas)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        jp = self.jp_datas[index]\n",
    "        en = self.en_datas[index]\n",
    "        return jp,en\n",
    "\n",
    "class DataLoaderCreater:\n",
    "\n",
    "    def __init__(self, src_tokenizer, tgt_tokenizer):\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def build_vocab(self, texts, tokenizer):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(tokenizer(text))\n",
    "        specials = ['<unk>', '<pad>', '<start>', '<end>']\n",
    "        v = vocab(counter, specials=specials, min_freq=2)   #1回しか出てきていない単語は語彙に入れない\n",
    "        v.set_default_index(v['<unk>'])\n",
    "        return v\n",
    "\n",
    "    def convert_text_to_indexes(self, text, vocab, tokenizer):\n",
    "        return [vocab['<start>']] + [\n",
    "            vocab[token] if token in vocab else vocab['<unk>'] for token in tokenizer(text.strip(\"\\n\"))\n",
    "        ] + [vocab['<end>']]\n",
    "\n",
    "    def create_dataloader(self, jp_list, en_list, collate_fn):\n",
    "        vocab_src = self.build_vocab(jp_list, tokenizer_src)\n",
    "        vocab_tgt = self.build_vocab(en_list, tokenizer_tgt)\n",
    "        self.vocab_src_itos = vocab_src.get_itos()\n",
    "        self.vocab_tgt_itos = vocab_tgt.get_itos()\n",
    "        self.vocab_src_stoi = vocab_src.get_stoi()\n",
    "        self.vocab_tgt_stoi = vocab_tgt.get_stoi()\n",
    "        self.vocab_size_src = len(self.vocab_src_stoi)\n",
    "        self.vocab_size_tgt = len(self.vocab_tgt_stoi)\n",
    "\n",
    "        src_data = [torch.tensor(self.convert_text_to_indexes(jp_data, self.vocab_src_stoi, self.src_tokenizer)) for jp_data in jp_list]\n",
    "        tgt_data = [torch.tensor(self.convert_text_to_indexes(en_data, self.vocab_tgt_stoi, self.tgt_tokenizer)) for en_data in en_list]\n",
    "        dataset = datasets(src_data, tgt_data)\n",
    "\n",
    "        dataloader = DataLoader(dataset, batch_size=64, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "PADDING_ID = 1\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PADDING_ID,  batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PADDING_ID, batch_first=True)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "dataloader_creater = DataLoaderCreater(tokenizer_src, tokenizer_tgt)\n",
    "train_dataloader = dataloader_creater.create_dataloader(jp_list=train_jp_list, en_list=train_en_list, collate_fn=collate_fn)\n",
    "vocab_size_src = dataloader_creater.vocab_size_src\n",
    "vocab_size_tgt = dataloader_creater.vocab_size_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "# EncodingとEmbeddingの違い\n",
    "# 学習を行わないのがPositional Encoding\n",
    "# 学習を行うのがPositional Embedding\n",
    "\n",
    "class PositionalEncoding():\n",
    "    def __init__(self, embedding_dim, len_sequence):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.len_sequence = len_sequence\n",
    "\n",
    "    def get_sin(self,i,k):\n",
    "        return torch.sin(torch.tensor(i/(10000)**(k/self.len_sequence)))\n",
    "\n",
    "    def get_cos(self,i,k):\n",
    "        return torch.cos(torch.tensor(i/(10000)**(k/self.len_sequence)))\n",
    "\n",
    "    def get_positional_vector(self):\n",
    "        pe = torch.zeros(self.len_sequence, self.embedding_dim)\n",
    "        for pos in range(self.len_sequence):\n",
    "            for i in range(0, int(self.embedding_dim/2)):\n",
    "                pe[pos, 2*i] = self.get_sin(pos, i)\n",
    "                pe[pos, 2*i+1] = self.get_cos(pos, i)\n",
    "        return pe\n",
    "\n",
    "\n",
    "# Transformerモデルの定義\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size_src, vocab_size_tgt, embedding_dim, num_heads, num_layers, device,  dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        # Positional Encoderを加算する必要あり\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_src = nn.Embedding(vocab_size_src, embedding_dim)\n",
    "        self.embedding_tgt = nn.Embedding(vocab_size_tgt, embedding_dim)\n",
    "        self.transformer = nn.Transformer(d_model=embedding_dim, nhead=num_heads, num_encoder_layers=num_layers, num_decoder_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(embedding_dim, vocab_size_tgt)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding_src(src).to(self.device)\n",
    "        tgt = self.embedding_tgt(tgt).to(self.device)\n",
    "        batch_size = src.shape[0]\n",
    "        pos_src = PositionalEncoding(self.embedding_dim, src.shape[1]).get_positional_vector().to(self.device)\n",
    "        pos_src = pos_src.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        pos_tgt = PositionalEncoding(self.embedding_dim, tgt.shape[1]).get_positional_vector().to(self.device)\n",
    "        pos_tgt = pos_tgt.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        src = src + pos_src\n",
    "        tgt = tgt + pos_tgt\n",
    "        output = self.transformer(src, tgt)\n",
    "        output = self.fc_out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.48 GiB. GPU \u0003 has a total capacity of 47.54 GiB of which 2.43 GiB is free. Process 2834466 has 29.90 GiB memory in use. Including non-PyTorch memory, this process has 15.20 GiB memory in use. Of the allocated memory 13.87 GiB is allocated by PyTorch, and 166.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m---> 34\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m model(src, tgt)\n\u001b[1;32m     24\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#なぜ(バッチサイズ、　シークエンス長、　vocab_size) => (バッチサイズ、　vocab_size、　シークエンス長)にする必要があるのか\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\u001b[38;5;66;03m##ここが問題　r\u001b[39;00m\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.48 GiB. GPU \u0003 has a total capacity of 47.54 GiB of which 2.43 GiB is free. Process 2834466 has 29.90 GiB memory in use. Including non-PyTorch memory, this process has 15.20 GiB memory in use. Of the allocated memory 13.87 GiB is allocated by PyTorch, and 166.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# モデルのハイパーパラメータ\n",
    "embedding_dim = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "lr_rate = 1e-5\n",
    "\n",
    "# モデルの初期化\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "model = TransformerModel(vocab_size_src, vocab_size_tgt, embedding_dim, num_heads, num_layers, device).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PADDING_ID)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_rate)\n",
    "\n",
    "# トレーニングループ\n",
    "num_epochs = 100\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (src, tgt) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        output = model(src, tgt)\n",
    "        output = output.permute(0, 2, 1) #なぜ(バッチサイズ、　シークエンス長、　vocab_size) => (バッチサイズ、　vocab_size、　シークエンス長)にする必要があるのか\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()##ここが問題　r\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        del src, tgt, output, loss  # メモリ解放\n",
    "        torch.cuda.empty_cache()\n",
    "    return epoch_loss/len(dataloader)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss = train_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model_weight.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
